# Dynamic Multi-Agent Scraping Guide

## ğŸ¯ Overview

This system replaces the problematic BatchProcessor threading approach with CrewAI's native multi-agent orchestration to eliminate the "signal only works in main thread" errors while maintaining concurrent scraping capabilities.

## ğŸ¤– How Dynamic Agent Delegation Works

### The Complete Flow

```
1. User Selection
   â”œâ”€â”€ Vendors: ASDA, Tesco, etc.
   â”œâ”€â”€ Categories: Electronics, Clothing, etc.
   â””â”€â”€ Scope: Recent (3 pages) vs Complete (all pages)
   
2. Plan Creation
   â”œâ”€â”€ Session ID: scraping_20250803_203045
   â”œâ”€â”€ Scope Configuration: max_pages = 3 or None
   â”œâ”€â”€ Estimated Products & Duration
   â””â”€â”€ URL Extraction from Categories
   
3. Multi-Agent Category Scraping (No Discovery Needed!)
   â”œâ”€â”€ CLI provides direct URLs:
   â”‚   â”œâ”€â”€ "https://groceries.asda.com/dept/food-cupboard/tinned-food_1215286"
   â”‚   â”œâ”€â”€ "https://groceries.asda.com/dept/fresh-food/fruit_1215135"
   â”‚   â””â”€â”€ "https://groceries.asda.com/dept/fresh-food/vegetables_1215136"
   â”‚
   â”œâ”€â”€ Category Crew #1 (Tinned Food)
   â”‚   â”œâ”€â”€ ProductScraperAgent: Extracts products directly from page (Browserbase session #1)
   â”‚   â”œâ”€â”€ DataExtractorAgent: Standardizes prices/images (Browserbase session #2)
   â”‚   â””â”€â”€ DataValidatorAgent: Validates final output (ProductDataValidator)
   â”‚
   â”œâ”€â”€ Category Crew #2 (Fruit)
   â”‚   â”œâ”€â”€ ProductScraperAgent: Extracts products directly from page (Browserbase session #3)
   â”‚   â”œâ”€â”€ DataExtractorAgent: Standardizes prices/images (Browserbase session #4)
   â”‚   â””â”€â”€ DataValidatorAgent: Validates final output (ProductDataValidator)
   â”‚
   â””â”€â”€ Category Crew #3 (Vegetables)
       â”œâ”€â”€ ProductScraperAgent: Extracts products directly from page (Browserbase session #5)
       â”œâ”€â”€ DataExtractorAgent: Standardizes prices/images (Browserbase session #6)
       â””â”€â”€ DataValidatorAgent: Validates final output (ProductDataValidator)
   
4. CrewAI Orchestration
   â”œâ”€â”€ Runs agents concurrently (no threading issues!)
   â”œâ”€â”€ Each agent operates independently
   â”œâ”€â”€ Automatic error isolation
   â””â”€â”€ Results combined into final dataset
```

## ğŸ”§ Key Components

### 1. Scope Configuration

```python
SCRAPING_SCOPES = {
    "recent": {
        "name": "Recent products only",
        "description": "First 2-3 pages per category (faster, good for testing)",
        "max_pages": 3
    },
    "complete": {
        "name": "All available products", 
        "description": "Complete product catalog (comprehensive, slower)",
        "max_pages": None
    }
}
```

**How it works:**
- User selects scope during interactive setup
- `max_pages` parameter passed to each SubCategoryScraperAgent
- Agents respect pagination limits based on scope

### 2. Plan Integration

```python
plan = {
    "session_id": "scraping_20250803_203045",
    "scope": "recent",
    "vendors": {...},
    "total_estimated_products": 500,
    "estimated_duration_minutes": 30
}
```

**How it works:**
- Plan created during interactive setup
- Session ID used for tracking and logging
- Scope configuration passed to dynamic scraper
- Progress tracked against plan estimates

### 3. Multi-Agent Crew Creation

```python
# For each URL from CLI selection, create a specialized crew
category_data = {
    "name": "Tinned Food",
    "url": "https://groceries.asda.com/dept/food-cupboard/tinned-food_1215286"
}

# Create specialized agents (like main.py)
product_scraper = CategoryScraperAgent.create_product_scraper_agent("Tinned Food", agent_id=1)
data_extractor = CategoryScraperAgent.create_data_extractor_agent("Tinned Food", agent_id=2)
data_validator = CategoryScraperAgent.create_data_validator_agent("Tinned Food", agent_id=3)

# Create tasks for each agent
scraping_task = CategoryScraperAgent.create_product_scraping_task(category_data, "asda", product_scraper, max_pages=3)
extraction_task = CategoryScraperAgent.create_data_extraction_task(category_data, "asda", data_extractor)
validation_task = CategoryScraperAgent.create_data_validation_task(category_data, "asda", data_validator)

# Execute with multi-agent crew
crew = Crew(
    agents=[product_scraper, data_extractor, data_validator],
    tasks=[scraping_task, extraction_task, validation_task],
    process=Process.sequential
)
```

**How it works:**
- **Multi-agent crew per category** (like main.py architecture)
- **Specialized roles**: Product extraction â†’ Data standardization â†’ Validation
- **Tool distribution**: Each agent gets only the tools they need
- **Sequential processing**: Extract â†’ Standardize â†’ Validate pipeline
- **Independent Browserbase sessions** for extraction and standardization agents
- **Scope integration**: Max pages passed to extraction task only
- **Direct product access**: First step extracts products immediately (no navigation needed)

## ğŸš€ Advantages Over BatchProcessor

| Aspect | BatchProcessor (Old) | Dynamic Agents (New) |
|--------|---------------------|---------------------|
| **Threading** | Custom worker threads â†’ Signal errors | CrewAI native execution âœ… |
| **Concurrency** | Fixed thread pool | One agent per CLI-selected URL âœ… |
| **Error Handling** | Batch-level failures | Agent-level isolation âœ… |
| **Scope Integration** | âŒ Not implemented | âœ… Fully integrated |
| **Plan Tracking** | âŒ Limited | âœ… Session ID + progress |
| **Observability** | Basic batch progress | Per-agent detailed logging âœ… |
| **URL Usage** | âŒ Ignored CLI selections | âœ… Direct scraping of CLI URLs |
| **Unnecessary Discovery** | âŒ N/A | âœ… Eliminated - no CategoryDiscoveryAgent |

## ğŸ“Š Scope Impact Examples

### Recent Scope (max_pages: 3)
```
Electronics Category
â”œâ”€â”€ Phones: Pages 1-3 â†’ ~75 products
â”œâ”€â”€ Laptops: Pages 1-3 â†’ ~75 products  
â””â”€â”€ Tablets: Pages 1-3 â†’ ~75 products
Total: ~225 products in ~6 minutes
```

### Complete Scope (max_pages: None)
```
Electronics Category  
â”œâ”€â”€ Phones: All pages â†’ ~500 products
â”œâ”€â”€ Laptops: All pages â†’ ~400 products
â””â”€â”€ Tablets: All pages â†’ ~300 products
Total: ~1200 products in ~30 minutes
```

## ğŸ” Session Tracking

Each scraping session gets:
- **Unique Session ID**: `scraping_20250803_203045`
- **Plan File**: `scraping_plans/scraping_20250803_203045.json`
- **Agent Logs**: Individual agent progress and results
- **Progress Tracking**: Real-time updates per agent

## ğŸ› ï¸ Configuration

### Dynamic Scraper Initialization
```python
dynamic_scraper = DynamicMultiAgentScraper(
    max_concurrent_agents=3,           # Max agents per category
    max_pages_per_category=3,          # From scope selection
    session_id="scraping_20250803_203045"  # From plan
)
```

### Agent Task Configuration
```python
task_description = f"""
Scrape products from: {subcategory['name']}
Max pages to scrape: {max_pages or 'All available'}

Your task is to:
1. Navigate to the subcategory page
2. Extract all visible products with complete details
3. Handle pagination to get products from up to {max_pages} pages
4. Validate and standardize the product data
...
"""
```

## ğŸ¯ Next Steps

1. **Test the Integration**: Run `python enhanced_interactive_scraper.py`
2. **Monitor Agent Behavior**: Check that scope limits are respected
3. **Verify Session Tracking**: Ensure plan files are created correctly
4. **Performance Testing**: Compare recent vs complete scope timing

The dynamic agent approach maintains all the planning and scoping functionality while eliminating threading issues through CrewAI's native orchestration capabilities.
